{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('pytorch38': conda)"
  },
  "interpreter": {
   "hash": "d0b7bbab015f35d2a2a0ab8bc50ddb026f5ad518bb64d832c3205ac322f5cd58"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "from torch.utils.data.dataset import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "from DataSet import MyDataSet\n",
    "import pandas as pd\n",
    "import Net\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.io as io\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import Process\n",
    "from pathlib import Path\n",
    "import MySampler\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGBimagePaths = [str(p) for p in Path(\"\").glob(\"*.png\")]\n",
    "\n",
    "#前処理の宣言\n",
    "transform = nn.Sequential(\n",
    "    #transforms.ToPILImage(),\n",
    "    transforms.Resize((200, 200)),\n",
    "    #transforms.ToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float32),\n",
    "    transforms.Normalize(0.5, 0.5),\n",
    ").cuda()\n",
    "\n",
    "print(RGBimagePaths[0])\n",
    "RGBimage = io.read_image(path=RGBimagePaths[0], mode=io.image.ImageReadMode.RGB)\n",
    "GrayImage = io.read_image(path=RGBimagePaths[0], mode=io.image.ImageReadMode.GRAY)\n",
    "\n",
    "RGBimage = np.transpose(RGBimage.numpy(), (1, 2, 0))\n",
    "GrayImage = transform(GrayImage)\n",
    "GrayImage = np.transpose((GrayImage.numpy() + 1) / 2 * 256, (1, 2, 0))\n",
    "\n",
    "after = GrayImage\n",
    "after = cv2.bilateralFilter(after, 5, sigmaColor=20, sigmaSpace=20)\n",
    "bilateral = after\n",
    "clahe = cv2.createCLAHE(clipLimit=2, tileGridSize=(8,8))\n",
    "after = clahe.apply(after.astype(np.uint8))\n",
    "#after = cv2.equalizeHist(after)\n",
    "\n",
    "#ret, after = cv2.threshold(after, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "#rgb_npimg = np.squeeze(rgb_npimg, 0)\n",
    "#rgb_npimg = (rgb_npimg + 1.0) / 2.0\n",
    "plt.imshow(RGBimage)\n",
    "plt.show()\n",
    "plt.imshow(GrayImage, cmap=\"gray\")\n",
    "plt.show()\n",
    "plt.imshow(bilateral, cmap=\"gray\")\n",
    "plt.show()\n",
    "plt.imshow(after, cmap=\"gray\")\n",
    "plt.show()\n",
    "plt.hist(GrayImage.ravel(), bins=256)\n",
    "plt.show()\n",
    "plt.hist(after.ravel(), bins=256)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGBimagePaths = [str(p) for p in Path(\"\").glob(\"*.png\")]\n",
    "\n",
    "#前処理の宣言\n",
    "transform = nn.Sequential(\n",
    "    #transforms.ToPILImage(),\n",
    "    transforms.Resize((200, 200)),\n",
    "    #transforms.ToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float32),\n",
    "    transforms.Normalize(0.5, 0.5),\n",
    ").cuda()\n",
    "\n",
    "print(RGBimagePaths[0])\n",
    "RGBimage = io.read_image(path=RGBimagePaths[0], mode=io.image.ImageReadMode.RGB)\n",
    "GrayImage = io.read_image(path=RGBimagePaths[0], mode=io.image.ImageReadMode.GRAY)\n",
    "\n",
    "RGBimage = np.transpose(RGBimage.numpy(), (1, 2, 0))\n",
    "GrayImage = transform(GrayImage)\n",
    "GrayImage = np.transpose((GrayImage.numpy() + 1) / 2 * 256, (1, 2, 0))\n",
    "\n",
    "after = GrayImage\n",
    "after = cv2.bilateralFilter(after, 5, sigmaColor=20, sigmaSpace=20)\n",
    "bilateral = after\n",
    "after = cv2.equalizeHist(after.astype(np.uint8))\n",
    "#clahe = cv2.createCLAHE(clipLimit=2, tileGridSize=(8,8))\n",
    "#after = clahe.apply(after.astype(np.uint8))\n",
    "\n",
    "ret, nichi = cv2.threshold(after, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "#rgb_npimg = np.squeeze(rgb_npimg, 0)\n",
    "#rgb_npimg = (rgb_npimg + 1.0) / 2.0\n",
    "plt.imshow(RGBimage)\n",
    "plt.show()\n",
    "plt.imshow(GrayImage, cmap=\"gray\")\n",
    "plt.show()\n",
    "plt.imshow(bilateral, cmap=\"gray\")\n",
    "plt.show()\n",
    "plt.imshow(after, cmap=\"gray\")\n",
    "plt.show()\n",
    "plt.imshow(nichi, cmap=\"gray\")\n",
    "plt.show()\n",
    "plt.hist(GrayImage.ravel(), bins=256)\n",
    "plt.show()\n",
    "plt.hist(after.ravel(), bins=256)\n",
    "plt.show()\n",
    "plt.hist(nichi.ravel(), bins=256)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data.dataset import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "from DataSet import MyDataSet\n",
    "import pandas as pd\n",
    "import Net\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.io as io\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import Process\n",
    "from pathlib import Path\n",
    "import MySampler\n",
    "\n",
    "#学習率スケジューラ\n",
    "class LearningRateScheduler:\n",
    "    def __init__(self, base_lr: float, max_epoch: int, power=0.9):\n",
    "        self.max_epoch = max_epoch\n",
    "        self.base_lr = base_lr\n",
    "        self.power = power\n",
    "\n",
    "    def __call__(self, epoch: int):\n",
    "        if epoch <= 5:\n",
    "            return self.base_lr * (epoch + 1) / 5\n",
    "        return (1 - max(epoch - 6, 1) / self.max_epoch) ** self.power * self.base_lr\n",
    "\n",
    "#############\n",
    "###~~訓練~~###\n",
    "##############\n",
    "#model.train()\n",
    "#scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "def loop():\n",
    "    #データセットの定義\n",
    "    dataSet = MyDataSet(imageSize=200)\n",
    "\n",
    "    data_size = len(dataSet)\n",
    "    train_size = int(data_size * 0.8)\n",
    "    val_size = int(data_size * 0.1)\n",
    "    test_size = data_size - train_size - val_size\n",
    "\n",
    "    \"\"\"\n",
    "    train_indices = list(range(0, train_size))\n",
    "    val_indices = list(range(train_size, data_size + val_size))\n",
    "    test_indices = list(range(train_size + val_size, data_size))\n",
    "\n",
    "    train_dataset = Subset(dataSet, train_indices)\n",
    "    val_dataset = Subset(dataSet, val_indices)\n",
    "    test_dataset = Subset(dataSet, test_indices)\n",
    "    \"\"\"\n",
    "\n",
    "    dataLoader = DataLoader(dataset=dataSet, batch_size=1, shuffle=False, num_workers=os.cpu_count(), pin_memory=True)\n",
    "\n",
    "    #学習の準備\n",
    "    model = Net.MyResNet50(1)           #モデルの読み込み\n",
    "    model = model.cuda()\n",
    "    criterion = nn.MSELoss()            #損失関数は平均2乗誤差\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    epoch = 200\n",
    "    lr = 1e-3\n",
    "    lr_scheduler = LearningRateScheduler(lr, epoch)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_scheduler)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    i = 0\n",
    "    for (RGBimage, DepthImage, x, y, z) in dataLoader:\n",
    "        if i < 3 or i == 14313 or i == 14314 or i == 23110:\n",
    "            rgb_npimg = RGBimage.numpy()\n",
    "            depth_npimg = DepthImage.numpy()\n",
    "            rgb_npimg = np.squeeze(rgb_npimg, 0)\n",
    "            depth_npimg = np.squeeze(depth_npimg, 0)\n",
    "\n",
    "            rgb_npimg = (rgb_npimg + 1.0) / 2.0\n",
    "            depth_npimg = (depth_npimg + 1.0) / 2.0\n",
    "            plt.imshow(np.transpose(rgb_npimg, (1, 2, 0)))\n",
    "            plt.show()\n",
    "            plt.imshow(np.transpose(depth_npimg, (1, 2, 0)))\n",
    "            plt.show()\n",
    "\n",
    "            print(\"i=\" + str(i))\n",
    "            print(\"x=\" + str(x))\n",
    "            print(\"y=\" + str(y))\n",
    "\n",
    "        i += 1\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#データセットの定義\n",
    "dataSet = MyDataSet(imageSize=200)\n",
    "\n",
    "data_size = len(dataSet)\n",
    "train_size = int(data_size * 0.8)\n",
    "val_size = int(data_size * 0.1)\n",
    "test_size = data_size - train_size - val_size\n",
    "\n",
    "\"\"\"\n",
    "train_indices = list(range(0, train_size))\n",
    "val_indices = list(range(train_size, data_size + val_size))\n",
    "test_indices = list(range(train_size + val_size, data_size))\n",
    "\n",
    "train_dataset = Subset(dataSet, train_indices)\n",
    "val_dataset = Subset(dataSet, val_indices)\n",
    "test_dataset = Subset(dataSet, test_indices)\n",
    "\"\"\"\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataSet, (train_size, val_size, test_size))\n",
    "\n",
    "#データローダーの定義\n",
    "batchSize = 64\n",
    "print(\"cpu_count:\" + str(os.cpu_count()))\n",
    "#sampler = MySampler.MySampler(batch_size=batchSize, shuffle=True, sampler=train_dataset)\n",
    "trainLoader = DataLoader(train_dataset, batch_size=batchSize, shuffle=True,num_workers = os.cpu_count(), pin_memory = True)\n",
    "valLoader = DataLoader(val_dataset, batch_size= 1, shuffle=False, num_workers = os.cpu_count(), pin_memory = True)\n",
    "testLoader = DataLoader(test_dataset, batch_size= 1, shuffle=False, num_workers = os.cpu_count(), pin_memory = True)\n",
    "\n",
    "#学習の準備\n",
    "model = Net.MyResNet50(1)           #モデルの読み込み\n",
    "model = model.cuda()\n",
    "criterion = nn.MSELoss()            #損失関数は平均2乗誤差\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "i = 0\n",
    "for(RGBimage, DepthImage, x, y, z) in trainLoader:\n",
    "    print(RGBimage.shape)\n",
    "    print(DepthImage.shape)\n",
    "\n",
    "    #RGBimage = RGBimage.view(RGBimage.shape[2], RGBimage.shape[0], RGBimage.shape[1])\n",
    "    rgb_npimg = RGBimage.numpy()\n",
    "    depth_npimg = DepthImage.numpy()\n",
    "    print(rgb_npimg.shape)\n",
    "    #print(npimg.shape)\n",
    "    rgb_npimg = np.squeeze(rgb_npimg, 0)\n",
    "    depth_npimg = np.squeeze(depth_npimg, 0)\n",
    "\n",
    "    rgb_npimg = (rgb_npimg + 1.0) / 2.0\n",
    "    depth_npimg = (depth_npimg + 1.0) / 2.0\n",
    "    plt.imshow(np.transpose(rgb_npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    plt.imshow(np.transpose(depth_npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "    if i == 10:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "    #print(np.transpose(npimg, (1, 2, 0)))\n",
    "    #RGBimage = RGBimage.view(RGBimage.shape[1], RGBimage.shape[2], RGBimage.shape[0])\n",
    "    #plt.imshow(DepthImage)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習率スケジューラ\n",
    "class LearningRateScheduler:\n",
    "    def __init__(self, base_lr: float, max_epoch: int, power=0.9):\n",
    "        self.max_epoch = max_epoch\n",
    "        self.base_lr = base_lr\n",
    "        self.power = power\n",
    "\n",
    "    def __call__(self, epoch: int):\n",
    "        if epoch <= 5:\n",
    "            return self.base_lr * (epoch + 1) / 5\n",
    "        return (1 - max(epoch - 6, 1) / self.max_epoch) ** self.power * self.base_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#############\n",
    "###~~訓練~~###\n",
    "##############\n",
    "#model.train()\n",
    "#scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "epoch = 200\n",
    "lr = 1e-3\n",
    "lr_scheduler = LearningRateScheduler(lr, epoch)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_scheduler)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "writer = SummaryWriter(log_dir=\"./logs/epoch200-4\")\n",
    "\n",
    "for i in range(epoch):\n",
    "    model.train()\n",
    "    test_loss = 0\n",
    "    torch.set_grad_enabled(True)\n",
    "    step = 0\n",
    "\n",
    "    for(RGBimage, DepthImage, x, y, z) in trainLoader:\n",
    "        #訓練データの初期化\n",
    "        RGBimage = RGBimage.cuda()      \n",
    "        DepthImage = DepthImage.cuda()\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        z = z.cuda()     \n",
    "\n",
    "        #勾配の初期化       \n",
    "        optimizer.zero_grad()  \n",
    "        print(\"initialized\")\n",
    "\n",
    "        #混合精度計算部\n",
    "        with torch.cuda.amp.autocast():\n",
    "            #学習\n",
    "            #with torch.cuda.amp.autocast():\n",
    "            out_x, out_y, out_z = model(RGBimage, DepthImage) \n",
    "            x = x.unsqueeze(1)\n",
    "            y = y.unsqueeze(1)\n",
    "            z = z.unsqueeze(1)\n",
    "\n",
    "            loss_x = criterion(out_x.float(), x.float())\n",
    "            loss_y = criterion(out_y.float(), y.float())\n",
    "            loss_z = criterion(out_z.float(), z.float())\n",
    "        \n",
    "        print(\"AMP Clear\")\n",
    "\n",
    "        #3つの損失を適当な重みをかけて束ねる\n",
    "        loss = (loss_x + loss_y + loss_z) / 3.0    \n",
    "        test_loss += loss\n",
    "        #loss = loss.float()\n",
    "\n",
    "        print(step)\n",
    "        step += 1\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        #loss.backward()\n",
    "        #optimizer.step()\n",
    "        scaler.update()\n",
    "        print(\"update Clear\")\n",
    "\n",
    "        del loss_x, loss_y, loss_z, RGBimage, DepthImage, x, y, z, loss\n",
    "    \n",
    "    test_loss /= test_size\n",
    "    writer.add_scalars(\"losses\", { \"loss_size200_lr1e-3_batch64_pow09\": test_loss, } , i)\n",
    "    #writer.add_histogram(\"fc_x.weights\", model.fc_x.weight, i)\n",
    "    #writer.add_histogram(\"fc_y.weights\", model.fc_y.weight, i)\n",
    "    #writer.add_histogram(\"fc_z.weights\", model.fc_z.weight, i)\n",
    "    del test_loss\n",
    "\n",
    "    #バリデーションロス計算\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    val_step = 1\n",
    "    torch.set_grad_enabled(False)\n",
    "    for (RGBimage, DepthImage, x, y, z) in valLoader:\n",
    "        print(\"ValStep:\" + str(val_step) + \" / \" + str(val_size))\n",
    "        val_step += 1\n",
    "        RGBimage = RGBimage.cuda()\n",
    "        DepthImage = DepthImage.cuda()\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        z = z.cuda()     \n",
    "\n",
    "        out_x, out_y, out_z = model(RGBimage, DepthImage) \n",
    "        x = x.unsqueeze(1)\n",
    "        y = y.unsqueeze(1)\n",
    "        z = z.unsqueeze(1)\n",
    "\n",
    "        loss_x = criterion(out_x.float(), x.float())\n",
    "        loss_y = criterion(out_y.float(), y.float())\n",
    "        loss_z = criterion(out_z.float(), z.float())\n",
    "\n",
    "        #3つの損失を適当な重みをかけて束ねる\n",
    "        loss += (loss_x + loss_y + loss_z) / 3.0\n",
    "\n",
    "        del loss_x, loss_y, loss_z, RGBimage, DepthImage, x, y, z\n",
    "\n",
    "    loss /= val_size\n",
    "\n",
    "    writer.add_scalars(\"losses\", {\"val-loss_size200_lr1e-3_batch64_pow09\": loss,} ,\n",
    "                                    i)\n",
    "    writer.add_scalar(\"Lerning Rate\", np.array(scheduler.get_lr()), i)\n",
    "    print(\"lr=\" + str(scheduler.get_lr()))\n",
    "\n",
    "    print(\"epoch: \" + str(i + 1) + \" / \" + str(epoch))\n",
    "\n",
    "    \"\"\"\n",
    "        学習率スケジューラ\n",
    "    \"\"\"\n",
    "    scheduler.step()\n",
    "\n",
    "torch.save(model.to(\"cpu\").state_dict(), os.getcwd() + \"/epoch200_size200_lr1e-3__batch64_pow09.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.get_image_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net.MyResNet50(1)\n",
    "model = model.cuda()\n",
    "model.load_state_dict(torch.load(\"lightPos.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.to(\"cpu\").state_dict(), os.getcwd() + \"/lightPosCPU.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model = Net.MyResNet50(1)\n",
    "#model.load_state_dict(torch.load(\"001-ep100\", map_location=torch.device(\"cpu\")))\n",
    "model.to(\"cpu\")\n",
    "i = 0\n",
    "dist = 0\n",
    "ave_dist = 0\n",
    "step = 0\n",
    "\n",
    "#print(model.state_dict().keys())\n",
    "\n",
    "\n",
    "for(RGBimage, DepthImage, x, y, z) in trainLoader:\n",
    "    #初期化\n",
    "    i += 1\n",
    "    if i > 100:\n",
    "        break\n",
    "\n",
    "    print(RGBimage.shape)\n",
    "    print(DepthImage.shape)\n",
    "\n",
    "    \"\"\"\n",
    "    if i >= 1:\n",
    "        #RGBimage = RGBimage.view(RGBimage.shape[2], RGBimage.shape[0], RGBimage.shape[1])\n",
    "        rgb_npimg = RGBimage.numpy()\n",
    "        depth_npimg = DepthImage.numpy()\n",
    "        print(rgb_npimg.shape)\n",
    "        #print(npimg.shape)\n",
    "        rgb_npimg = np.squeeze(rgb_npimg, 0)\n",
    "        depth_npimg = np.squeeze(depth_npimg, 0)\n",
    "\n",
    "        rgb_npimg = (rgb_npimg + 1.0) / 2.0\n",
    "        depth_npimg = (depth_npimg + 1.0) / 2.0\n",
    "        plt.imshow(np.transpose(rgb_npimg, (1, 2, 0)))\n",
    "        plt.show()\n",
    "        plt.imshow(np.transpose(depth_npimg, (1, 2, 0)))\n",
    "        plt.show()\n",
    "        #print(np.transpose(npimg, (1, 2, 0)))\n",
    "        #RGBimage = RGBimage.view(RGBimage.shape[1], RGBimage.shape[2], RGBimage.shape[0])\n",
    "        #plt.imshow(DepthImage)\n",
    "    \"\"\"\n",
    "\n",
    "    #テスト\n",
    "    out_x, out_y, out_z = model(RGBimage, DepthImage)\n",
    "    x = x.unsqueeze(1)\n",
    "    y = y.unsqueeze(1)\n",
    "    z = z.unsqueeze(1)\n",
    "\n",
    "    loss_x = criterion(out_x.float(), x.float())\n",
    "    loss_y = criterion(out_y.float(), y.float())\n",
    "    loss_z = criterion(out_z.float(), z.float())\n",
    "\n",
    "    loss = (loss_x + loss_y + loss_z) / 3.0\n",
    "\n",
    "    #TensorBoard書き込み\n",
    "    writer.add_scalars(\"Validation Losses\", {  \"loss\": loss, \n",
    "                                    \"loss_x\": loss_x,\n",
    "                                    \"loss_y\": loss_y,\n",
    "                                    \"loss_z\": loss_z}\n",
    "                                    , step)\n",
    "    step += 1\n",
    "    writer.close()\n",
    "\n",
    "    #正解座標との距離\n",
    "    dist = torch.sqrt((x - out_x) ** 2 + (y - out_y) ** 2 + (z - out_z) ** 2)\n",
    "    #print(\"dist: \" + str(dist))\n",
    "    #\"x[\" + str(i) + \"]: \" + str(x) + \"\\n\n",
    "    #print(\"out_x[\" + str(i) + \"]: \" + str(out_x))\n",
    "    print(\"out_x[\" + str(i) + \"]: \" + str(out_x))\n",
    "    print(\"out_y[\" + str(i) + \"]: \" + str(out_y))\n",
    "    print(\"out_z[\" + str(i) + \"]: \" + str(out_z))\n",
    "    ave_dist += dist\n",
    "\n",
    "print(\"ave_dist: \" + str(ave_dist / i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Net.MyResNet50(1)\n",
    "model = model.cuda()\n",
    "model.load_state_dict(torch.load(\"lightPos.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}